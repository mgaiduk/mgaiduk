{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZ2tiDrIQYgMQW5czVGNl0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgaiduk/mgaiduk/blob/main/grasp3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install  \"tensorflow-text==2.13.*\"\n",
        "%pip install \"tf-models-official==2.13.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAD_TmWlLcYP",
        "outputId": "3d569342-9cf8-409f-e361-4255d4cff81a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text==2.13.*\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.13.*) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text==2.13.*) (3.2.2)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.13.0\n",
            "Collecting tf-models-official==2.13.*\n",
            "  Downloading tf_models_official-2.13.2-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.0.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official==2.13.*)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.5.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.23.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.8.1.78)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (6.0.1)\n",
            "Collecting sacrebleu (from tf-models-official==2.13.*)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.11.3)\n",
            "Collecting sentencepiece (from tf-models-official==2.13.*)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official==2.13.*)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.9.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.13.*)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-text~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (6.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.34.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.13.*) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official==2.13.*)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official==2.13.*)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.13.*) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.5.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.41.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (6.1.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (1.61.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.13.*) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.13.*) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.2.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=dff1bd98df25134c85363ed75b93c018d85e49823f6931a9dd8633c166a90bf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: sentencepiece, tensorflow-model-optimization, portalocker, immutabledict, colorama, sacrebleu, seqeval, tf-models-official\n",
            "Successfully installed colorama-0.4.6 immutabledict-3.0.0 portalocker-2.8.2 sacrebleu-2.3.1 sentencepiece-0.1.99 seqeval-1.2.2 tensorflow-model-optimization-0.7.5 tf-models-official-2.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YANZoVbPH5Ru",
        "outputId": "aa5ef35d-df9c-436d-faa0-ca3f7af0b1e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import json\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "print(tf.__version__)\n",
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcSdgKBzH8Z8",
        "outputId": "b892e2ec-c94c-4d26-ecd6-3ec9e54ca165"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = []\n",
        "labels = []\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/samples-1680.jsonl\", \"r\") as file:\n",
        "  for line in file:\n",
        "    js = json.loads(line)\n",
        "    if not \"HR\" in js:\n",
        "      continue\n",
        "    prompts.append(js[\"prompt\"])\n",
        "    labels.append(js[\"HR\"])"
      ],
      "metadata": {
        "id": "0DKTjzl6IZpG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_prompts, test_prompts, train_labels , test_labels = train_test_split(prompts, labels, test_size = 0.2)"
      ],
      "metadata": {
        "id": "n2qrimPFJg-u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prompts = tf.constant(train_prompts)\n",
        "train_labels = tf.constant(train_labels)\n",
        "test_prompts = tf.constant(test_prompts)\n",
        "test_labels = tf.constant(test_labels)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_prompts, train_labels)).batch(32)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((test_prompts, test_labels)).batch(32)\n",
        "for r in train_ds:\n",
        "  break\n",
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXoydD-BJmFd",
        "outputId": "7e8887be-e0e4-4b57-deff-485700ed04df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              " array([b'In Great Britain, for example, some most pertinent thoughts on this subject were expressed in a notable Reservation to the Majority Report of the <Organization>, in the following language: \"On a review of the evidence we cannot but feel that there is considerable confusion in certain quarters with regard to the relation which exists between the care of the individual\\'s health and the wider question of the promotion of the health of the community.',\n",
              "        b'Objective:\\n\\nTo evaluate the performance of real-time CAD with endocytoscopes (\\xc3\\x97520 ultramagnifying colonoscopes providing microvascular and cellular visualization of colorectal polyps after application of the narrow-band imaging [NBI] and methylene blue staining modes, respectively).',\n",
              "        b'Without the embers burn a few times complete my landlady breakfasts were beau. I had said i noticed with that that taut jeans and were humored by and secure, is too. We stopped smooching each other forearm as if i had missing. The stag night, but because i distinct blue pill. There was sitting in her attractive we went well to the halls. Her warmth of times, if we had the horses home i will be heard. <Person> from the cubicle where it supreme joy buttons on top id attempt to rep as powerful attention. Petite anal first To be a logical notify astonishing she let his imagination. I unprejudiced to work one of those pants and with <Person> wasn her puffies. Witches were not post this stage region to leave.',\n",
              "        b'Este texto \\xc3\\xa9 disponibilizado nos termos da licen\\xc3\\xa7a Atribui\\xc3\\xa7\\xc3\\xa3o-CompartilhaIgual 3.0 N\\xc3\\xa3o Adaptada (CC BY-SA 3.0) da Creative Commons; pode estar sujeito a condi\\xc3\\xa7\\xc3\\xb5es adicionais.',\n",
              "        b'\\xe8\\xb2\\xb4\\xe5\\xa5\\xb3\\xe3\\x81\\xae\\xe9\\xa1\\x98\\xe6\\x9c\\x9b\\xe5\\x8f\\xb6\\xe3\\x81\\x88\\xe3\\x81\\xbe\\xe3\\x81\\x9b\\xe3\\x82\\x93\\xe3\\x81\\x8b\\xef\\xbc\\x9f \\xef\\xbd\\x9e\\xe9\\x9d\\x9e\\xe6\\x97\\xa5\\xe5\\xb8\\xb8\\xe3\\x82\\x92\\xe8\\xb2\\xaa\\xe3\\x82\\x8b\\xe5\\xa5\\xb3\\xe9\\x81\\x94\\xef\\xbd\\x9e Vol.36\\n\\nCan your wish do not come true? ~ Women who cling to extraordinary ~ Vol.36\\n\\n<URL>\\n\\n<URL>\\n\\n<URL>\\n\\n<URL>\\n\\n<URL>\\n\\n<URL>\\n\\nMy wife\\xe2\\x80\\x99s cheating party \\xe2\\x80\\xa6I wonder \\xe2\\x80\\xa6He was a girl! ! ! [View attention] Gangbang rape image No cut unedited \\xe2\\x80\\x9cWomen\\xe2\\x80\\x99s rape crime record\\xe2\\x80\\x9d cruelty!Coma with chloroform and stun gun,Insanely with aphrodisiac\\n\\n,Breast breasts crying and crying for impolite insult \\xe2\\x80\\x93 <Person>\\n\\nA man looking at an outdoor bath took a coma medicine and a coma he was doing 2\\n\\nAiming at the highest,Erotic and decoy infant lesbians ~ When the complex changes to charm \\xe2\\x80\\x93 Hamazaki Mao & Mandarin orange',\n",
              "        b'Telephone: <PhoneNumber> Address: <Address> Website: <URL> State motor vehicle agencies provide the National <Organization> Register with the names of individuals who have lost their privileges or who have been convicted of a serious traffic violation.',\n",
              "        b'U.K. officials entered Phase 2 calling for a more continuous approach to the talks, conscious of the time pressure, with U.K. businesses wanting a transition agreement in place by March to prevent them triggering contingency plans for the coming financial year that could see them move investment and activity out of the U.K.\\n\\n\\xe2\\x80\\x9cWe\\xe2\\x80\\x99re ready to work at pace across all issues \\xe2\\x80\\x94 implementation period, separation issues and future \\xe2\\x80\\x94 but it seems this is not being reciprocated at the moment,\\xe2\\x80\\x9d the first U.K. official said.',\n",
              "        b'Realistically, how often do you interact with the black community? Because I imagine that you are a shut-in introvert that interacts more with fictional characters than you do with the outside world.If someone was to put a gun to your head and force you to interact with black people and try to dial their \"intellect\" level back to the point where they aren\\'t acting like ignorant grunt monkeys would that alter your perception of African-Americans to a positive degree?',\n",
              "        b'He bore the cruel and unjust accusations of some of the brothers with humble calmness, but at the same time with the most happy results, since his irreproachable character was acknowledged He attached himself with special intimacy to a brother of the cloister, called <Person>, which may be accounted for by the circumstance that he bore the same name as his loved father.',\n",
              "        b'\\xe2\\x80\\x9cWe do not have much in the way of transfer deals in the pipeline, but we are still working extremely hard to improve the squad.\\xe2\\x80\\x9d\\n\\nThere may be no deals imminent, but <Person> has admitted an interest in <<Organization>\\xe2\\x80\\x99s \\xc2\\xa35m-rated centre-back <Person> and <<Organization>\\xe2\\x80\\x99s Ghanaian defender <Person>.',\n",
              "        b'On ne voyait plus que ses pieds nus sous la masse noire. Puis un hurlement strident. Le gorille avait arrach\\xc3\\xa9 de ses crocs les parties g\\xc3\\xa9nitales de l\\xe2\\x80\\x99esclave qui restait sur le sable en se vidant de son sang, <Organization> Ma\\xc3\\xaetresse \\xc3\\xa9clata de rire:\\xc2\\xab Moins belle mort, pas de jouissance et s\\xc3\\xbbrement plus douloureuse ! Mais une belle castration qui devrait te plaire ! !\\xe2\\x80\\xa6 \\xc2\\xbbSon rire redoubla :\\xc2\\xab Tu devrais te voir ! Cette t\\xc3\\xaate que tu fais ! Et ta position ridicule \\xc3\\xa0 \\xc3\\xaatre attach\\xc3\\xa9 en croix \\xc3\\xa0 poil sur ce lit avec ce minable bout de viande qui te sert de sexe tout recroquevill\\xc3\\xa9. Tu ne bandes plus, hein ? Et crois moi, tu n\\xe2\\x80\\x99es plus pr\\xc3\\xaat de bander avec ce qui t\\xe2\\x80\\x99attend. Mais ne te fais pas trop de souci, rien ne dit que tu seras mis \\xc3\\xa0 mort par un gorille ! Je t\\xe2\\x80\\x99ai montr\\xc3\\xa9 ces vid\\xc3\\xa9os \\xc3\\xa0 titre d\\xe2\\x80\\x99exemple, mais ton r\\xc3\\xb4le d\\xe2\\x80\\x99esclave sera peut-\\xc3\\xaatre diff\\xc3\\xa9rent. Mon client \\xc3\\xa0 d\\xe2\\x80\\x99autres passions que je te laisserai d\\xc3\\xa9couvrir par toi-m\\xc3\\xaame. Et puis peut-\\xc3\\xaatre seras tu employ\\xc3\\xa9 comme esclave par sa femme. Je ne la connais pas, mais il para\\xc3\\xaet qu\\xe2\\x80\\x99elle est ob\\xc3\\xa8se. Et encore plus dingue que son mari \\xc3\\xa0 ce que l\\xe2\\x80\\x99on dit\\xe2\\x80\\xa6A moins qu\\xe2\\x80\\x99ils ne d\\xc3\\xa9cident de te revendre \\xc3\\xa0 quelqu\\xe2\\x80\\x99un d\\xe2\\x80\\x99autre.',\n",
              "        b'He immediately stopped and walked around before her face.\\n\\n\"Why don\\'t you get on all fours,\" he said. <Person> took some pictures and added, \"Now squeeze those big boobs between your arms. Your husband\\'s gonna like this pose.\" Her breasts looked tremendous hanging down like this and it strained the material of her top so much, it almost looked like she was topless.\\n\\n\"Damn,\" he said. \"Hold the pose. The sun\\'s glaring off your sexy round ass.\" He grabbed the towel and walked behind her.',\n",
              "        b'Yes. That would have helped me. When I pulled the tank off my foot, I was really just hoping I still had all my toes.',\n",
              "        b'a woman sitting on a bench smoking a cigarette',\n",
              "        b'A wrist splint is a treatment used to reduce the amount of pain and swelling caused by a Carpal tunnel. A right splint is a treatment used to reduce the amount of pain and swelling caused by a thumb spica.',\n",
              "        b'Man Kills Wife And Posts Photo Of Her Dead Body On <Organization>\\n\\nA man has left his <Organization> friends utterly bewildered when he posted the image of his wife\\'s dead body, claiming he was her killer and trying to giver a queer reason why he killed her. A Florida man identified as <Person>, reportedly killed his wife and posted a photo of her dead body on <Organization> while confessing to the murder shot her in self-defense because lived in fear of her. According to <Organization> reports, the man\\xe2\\x80\\x99s attorney, <Person> said in court on Monday that the 33-year-old <Person>, was battered by his 27-year-old wife, <Person>, who he said was an avid user of synthetic drugs such as ecstasy, had violent tendencies and was deeply involved in the occult and Satan worship. <Person> said he will seek to introduce evidence to prove his claims on behalf of his client, who has been jailed since his arrest for the August 2013 murder and faces life in prison if convicted. <Person> and his wife when the going was good\\n\\nAfter shooting <Person> in their South Miami home, <Person> allegedly posted a photo of her corpse on <Organization>, admitting in a rambling post that he killed her. \"Im going to prison or death sentence for killing my wife love you miss you guys takecare <Organization> people you will see me in the news\\xe2\\x80\\x99 my wife was punching me and I am not going to stand anymore with the abuse so I did what I did I hope u understand me,\" <Person> wrote on the social media site. The photo showed <Person>\\xe2\\x80\\x99s body with her legs folded under her in the kitchen of their South Miami home and was captioned: \"RIP <Person>.\" The picture as <Person> posted on facebook\\n\\n',\n",
              "        b'Genre: Visual novel, 3DCG, Adventure, Big tits, Handjob, Masturbation\\n\\nVersion: 0.3b + compressed version + Download Android version 0.3b unofficial from Adult! Censorship: No\\n\\nAuthor: <Person>\\n\\nLast updated: 5 February 2020\\n\\nLanguage: English\\n\\nMade in: <Organization>\\n\\nSize: 1,46 GB 7Z / 1,54 GB UN7Z\\n\\nSize compressed: 561 MB 7Z / 637 MB UN7Z\\n\\nHow to Install Lucid Dream Remake Game:\\n\\nDownload the Crack Setup From the link given below. Click on run to start the installation process. Extract. Don\\xe2\\x80\\x99t need Crack Lucid Dream Remake\\n\\nClick on Finish, Now Restart the Computer. Play the game. Have fun?',\n",
              "        b'The gross margin rose by 3 full percentage points to 49.7 percent in the quarter, and the operating margin improved by 0.9 percentage points to 5.2 percent, thanks to foreign exchange gains and to lower product-related costs, partly offset by increased investments in advertising \\xe2\\x80\\x93 \\xe2\\x80\\x9cMake it Better\\xe2\\x80\\x9d is the brand\\xe2\\x80\\x99s new global tagline - and in product development.',\n",
              "        b\"Fucking his friends little angel! Sucking dark dick in hopes of chocolate cum. Help me take these off. Loading the next set of images Confiding in her dark lover. Mom helping her take a BBC in her mouth. Biggest dick shes ever seen! Don't let your parents hear you! Massing his thick black cock with my white ass. Black cocks are my favorite: Paying his black cock with innocent pussy.\",\n",
              "        b'Design and Specifications\\n\\n\\n\\n\\n\\n\\n\\n12 to 14-inch <Organization> ultraportable notebook specifications (larger image here)\\n\\n\\n\\nThe revised <Organization> Spectre x360 notebook models with Kaby Lake processors (13-w013dx and 13-w023dx) are using <<Organization>>\\xe2\\x80\\x99s top U-series chip in the 15W lineup, the dual-core Core i7 7500U running at 2.70GHz with 3.50GHz Turbo, along with Intel HD Graphics 620, and the choice of 8GB or 16GB of DDR3 1866MHz memory.',\n",
              "        b'u. \"<Person> panicked as he now realised that his ordeal was far from over. He pulled his mouth of the owners cock. \"You told me that sucking you would pay my debt?\" \"Listen sissy boy,\" he snapped. \"One cock sucking doesn\\'t aquatint to your bill. \\'\"I\\'m gonna get my $300 worth out of you and that includes me fucking that cute little tail of yours.\" \"NO. \"\"I won\\'t do it,\" I told him. He now stood and pulled his overalls up re attaching the clasps. \"Well then, I guess you don\\'t want your car that bad,\" he smirked. My mind raced and he was again in control, as he reached the door and grabbed the handle. I again had no out and would have to submit. \"Please. Please don\\'t go,\" I whimpered. \"I\\'ll do what ever you want. \"That evil grin returned too his mouth as he made his way back to me at the same time removing his overalls. \"Now that\\'s more like it. \"\"You try that again and you\\'ll never get you car,\" he laughed. \"Now what do you have to say?\\'I could feel myself start to choke up as I blurted out the words he wanted to hear. \"Please, I want your cock inside me. \"\"I can\\'t hear you,\" came his reply. \"I want you to fuck me. \"\"Well I guess I could do that,\" he laughed. \"Now get up on the bed and get that cute little boy pussy ready for me. \"I stumbled to the bed and climbed up on it, where I positioned myself on all fours. I felt him join me as he positioned himself behind and between my legs. Next I felt the coldness as he applied some grease to my anal opening and he slipped one, then a second finger inside me. I could feel my sphincter start to relax as well as the grease helped make their penetration of me easier. There was now a third finger joining the other two as I bit my lips so as not to cry out. He began to push and pull them in and out of me as he worked to get me ready for his cock to enter. I could feel my hole being stretched wide and I fought my reaction to get up and leave, as I needed my car. He would fuck me and then hopefully my debt would be paid. I now felt his cock head at my opening and he started to push it into my anal hole. It was starting to enter as it made its way with the help of the grease. I could hear him grunt as he pushed it deeper and deeper into me. \"Fuck you are one tight little cunt,\" he hissed. \"You never had cock in you before?\"I shock me head telling him that I was infact a virgin when it came to anal sex. There was a time that <Person> and I had discussed it but we had never tried. She was not so happy about her receiving but was happy to try a strap on for me and now here I was with the real thing deep inside me. The owner now began to fuck me pushing and pulling his cock in and out of me. His balls soon slapped my buttocks as he was in a good rhythm, attacking my virgin arse with his hard cock. He grabbed a hand full of my hair pulling my head back. \"Come on boy work with me. \"\"Fuck my cock with that cute tight hole of yours. \"I began to push back against his cock\\'s advance both in and out of me. I was feeling myself becoming hard and my body now wanted to be fucked. He slipped his hand under me, where taking my cock in it began to stroke me long and hard. My body tensed as he pulled on my cock and fucked my arse at the same time. I was being turned on and now wanted to be fucked, as I worked with him both pushing my buttocks back and rocking myself in his hand. Oh god it felt so good as his cock poked my prostate and my cock stiffened in his hand. I wanted him and I wanted to cum inside me. I didn\\'t care anymore as he could use me for his pleasure. His sweat dripped onto my back as he worked hard to get himself off. I gazed at the pictures on the wall and pictured myself as one of them being fucked by my new lover. I was panting and ready to shoot my load and ready for him to do the same. \"Yeah baby push that pussy back,\" he yelled. \"Work with me and we can both get off. \"\"You are one hot bitch, aint you?\"He was right. I was now his bitch and he was mating me. I could feel his rhythm intensify as he pumped me like the slut I had become. My cock was so fucking hard and I wanted to cum so bad. I was not prepared when with one last thrust he shot the first of his load into me. \"Oh fuckkkkkkkkkkkkkkkkkkk,\" he screamed as his cock pushed deep into my bowel. He continued to pound my opening hard shooting more and more cum into meMy own cock twitched and in an instant it too exploded shooting cum onto the pillow of the bed. It kept shooting and shooting as he shot every last drop he could express into me. I screamed with pleasure as I too started to complete my orgasm as the last of both our loads now came from each of our cocks until I slumped forward onto the bed with him still inside me. I felt his cock soften and I now lay exhausted as he removed his cock from my hole. It was now at my face as he told me to lick it off. I complied with his direction and he told me that my bill had been paid. As I got up my bottom ached, as did every muscle of my body. I showered and then headed for my car, vowing never to return but also knowing that one-day I might have to again need servicing from the mechanic.',\n",
              "        b\"Astrology isn't a viable personality trait and no one gives a fuck that you are a Saggitarious. Your future is bright, not because you have a future, but because you are destined to be a star of a strip club.\",\n",
              "        b'And most other people. Would you say that over half of the world is like <Person>?\\n\\n\\nYeah, it is democracy. Democracy is where everyone votes, and the majority vote wins. Mob rule has no votes.',\n",
              "        b'Sources\\n\\n<URL>\\n\\n<URL>\\n\\n<URL>\\n\\n<URL>\\n\\n<URL>',\n",
              "        b'Screens\\n\\nDownLoad\\n\\n<Organization>\\n\\n<URL>\\n\\n<URL>',\n",
              "        b\"Hey <Person>, we know its you again. Your pulling hood up to your hairline trick still doesn't work. And no, <Person> still doesn't post here.\",\n",
              "        b\"Don't force the marriage. Just make an app, hire officiants and therapists, charge customers a nominal fee, and require proof that they are 18 years of age and over and bam! You've got a lucrative business model right there!\",\n",
              "        b'Hinduism has it as Ganga is believed to have descended from the heavens . Muslims and Christian like most abrahamic religions just bury but Zoroastrians parsis and Jews put the body in a tower to be eaten by hawks vultures and maggot . Happy to help with any other questions',\n",
              "        b'I decided to give it hard to this little bitch. The teen slut gets down on her knees and starts sucking my cock hard. This little bitch could suck my dick for days. I let her gag on my rod for a bit longer until I decided to come all over that beautiful face and soft blonde hair. My cum was suddenly dripping from her face to those cute little tits. She looked amazing with her cute face covered in my sticky cum. Then I found her in the middle of one of her bouts of lust. I decided to lick her pussy until the teen slut was fully satisfied. The comment field is required. Thank you! Your comment has been sent for review. Unexpected error tub, please contact support.',\n",
              "        b'Got caught in a folding laundry drying rack.',\n",
              "        b'I almost didn\\'t write this because I know you will just look it over and pay no attention but don\\'t think ur original. You\\'re not the first to \"tack\" Jew on. It was done in ancient times when Jews ran financial businesses and were therefore well off and it was done to cause the Holocaust. Which did happen in case you think that was a lie as well. I know because I have people who died in it. All I ask is that you rethink \"tacking\" Jew on because it is a more significant statement that you think.\\nSome less fortunate and less educated person will see it and hate the Jews for it. And the Jews will have you to thank. The above correspondence left us shaking our heads.\\n\\nWhat a case of \"splitting a hair four ways.\" We would like to make it clear, for the umpteenth time, that we are neither anti-Jew nor anti-Semitic, but we are most definitely anti-Zionist. If the writer of this message has enough education to understand some of the problems of the origins of ancient anti-Semitism, i.e. that most financial business was relegated to those of the Jewish religion because charging interest was forbidden to Christians by the <Organization> and that, as a consequence, Jews very often found themselves acting as the middleman between the masses and the ruling classes, then he/she ought to realize that there is absolutely no historically justifiable reason for the land that belonged to the Palestinians (many of whom were Jews, by the way) should be given to a group of invading occupiers who based their claim on a religious belief. The roots of terrorism exist, for the most part, in that arbitrary land theft, and the subsequent occupation by foreigners. Certainly, some less fortunate and less educated people aren\\'t aware of this, including the above correspondent. Indeed, if Israel put down their weapons, there would be no more Israel.\\n\\nShouldn\\'t that tell us all something?',\n",
              "        b'What would you do, if you were a fourty year old <Person>, had big tits, and wanted somebody to fuck? You also got kindapped by me. And I had put you in my bedroom, naked and tied, to fuck you hard.'],\n",
              "       dtype=object)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
        "bert_model_name = \"bert_en_uncased_L-12_H-768_A-12\"\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJS4H4K4I65D",
        "outputId": "31f64cfb-173b-4113-e0b1-93b868a3a875"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkZ8pFtFJEfW",
        "outputId": "3f00e3ad-13b8-48da-bb67-106e6b11c9b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxGGkFOkJOFo",
        "outputId": "b9043fa4-2e7a-4b8e-ab1f-d3c200398f7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
            "Pooled Outputs Shape:(1, 768)\n",
            "Pooled Outputs Values:[-0.92169887 -0.39353466 -0.53931785  0.6825625   0.43848515 -0.14021172\n",
            "  0.87747127  0.26043358 -0.6311301  -0.9999658  -0.26320052  0.85105324]\n",
            "Sequence Outputs Shape:(1, 128, 768)\n",
            "Sequence Outputs Values:[[ 0.19451568  0.25141704  0.19075024 ... -0.24845096  0.38568568\n",
            "   0.13291004]\n",
            " [-0.5947861  -0.3942036   0.25245717 ... -0.7694675   1.1564167\n",
            "   0.32475695]\n",
            " [ 0.00641518 -0.15766475  0.5461027  ... -0.17451018  0.6028964\n",
            "   0.42672247]\n",
            " ...\n",
            " [ 0.21948306 -0.20927139  0.5386825  ...  0.24693541  0.1825099\n",
            "  -0.44427088]\n",
            " [ 0.01080238 -0.44553143  0.35990992 ...  0.3172276   0.2356278\n",
            "  -0.630706  ]\n",
            " [ 0.2932116  -0.10581895  0.6114753  ...  0.2074579   0.14494637\n",
            "  -0.35353395]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = hub.load(tfhub_handle_preprocess)\n",
        "def build_classifier_model():\n",
        "  input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='input')\n",
        "  tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
        "  tokenized_inputs = tokenize(input)\n",
        "  seq_length = 128  # Your choice here.\n",
        "  bert_pack_inputs = hub.KerasLayer(\n",
        "    preprocessor.bert_pack_inputs,\n",
        "    arguments=dict(seq_length=seq_length))  # Optional argument.\n",
        "  encoder_inputs = bert_pack_inputs([tokenized_inputs])\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation=None, name='dense1')(net)\n",
        "  return tf.keras.Model(input, net)\n",
        "classifier_model = build_classifier_model()\n",
        "classifier_model(r[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "210rjg4nJOus",
        "outputId": "5c8a0290-c706-4913-f01c-08739f6976a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
              "array([[-0.04249637],\n",
              "       [-0.82887995],\n",
              "       [ 0.22077744],\n",
              "       [-0.68148506],\n",
              "       [-0.25129414],\n",
              "       [-0.4411524 ],\n",
              "       [-0.03555377],\n",
              "       [-0.6815258 ],\n",
              "       [-0.1692827 ],\n",
              "       [-0.44889873],\n",
              "       [-0.12560216],\n",
              "       [ 0.04775489],\n",
              "       [-0.73498803],\n",
              "       [-0.870476  ],\n",
              "       [-0.32503855],\n",
              "       [-0.41160017],\n",
              "       [ 0.26620483],\n",
              "       [-0.6070614 ],\n",
              "       [ 0.17717999],\n",
              "       [-0.752297  ],\n",
              "       [ 0.05057841],\n",
              "       [-0.59428227],\n",
              "       [-0.38527995],\n",
              "       [-0.8160822 ],\n",
              "       [-0.6270472 ],\n",
              "       [-0.4832495 ],\n",
              "       [-0.7552974 ],\n",
              "       [-0.51741123],\n",
              "       [-0.4210317 ],\n",
              "       [-0.7238193 ],\n",
              "       [-0.6160564 ],\n",
              "       [-0.613596  ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()\n",
        "epochs = 5\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "metadata": {
        "id": "dLLNGgI-Kx5h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "umS4vaQfK6gy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_ds,\n",
        "                               validation_data=val_ds,\n",
        "                               epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhdXtftDK7Ti",
        "outputId": "a77493b5-c22f-4cb8-9be7-de67f1d3f523"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
            "Epoch 1/5\n",
            "37/37 [==============================] - 53s 955ms/step - loss: 0.3104 - binary_accuracy: 0.9472 - val_loss: 0.2188 - val_binary_accuracy: 0.9377\n",
            "Epoch 2/5\n",
            "37/37 [==============================] - 38s 1s/step - loss: 0.1689 - binary_accuracy: 0.9498 - val_loss: 0.1670 - val_binary_accuracy: 0.9377\n",
            "Epoch 3/5\n",
            "37/37 [==============================] - 40s 1s/step - loss: 0.1016 - binary_accuracy: 0.9506 - val_loss: 0.1457 - val_binary_accuracy: 0.9377\n",
            "Epoch 4/5\n",
            "37/37 [==============================] - 37s 1s/step - loss: 0.0405 - binary_accuracy: 0.9775 - val_loss: 0.1540 - val_binary_accuracy: 0.9619\n",
            "Epoch 5/5\n",
            "37/37 [==============================] - 37s 1s/step - loss: 0.0256 - binary_accuracy: 0.9887 - val_loss: 0.1593 - val_binary_accuracy: 0.9654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.save(\"/content/drive/MyDrive/Colab Notebooks/data/hr_moderation_model.wad\")"
      ],
      "metadata": {
        "id": "BFg5xGznK__q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calc f1 score\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "for batch in val_ds:\n",
        "  preds = classifier_model(batch[0])\n",
        "  for pred in preds:\n",
        "    p = pred[0].numpy()\n",
        "    all_preds.append(pred)\n",
        "  for label in batch[1]:\n",
        "    all_labels.append(label)\n",
        "len(all_preds), len(all_labels), all_preds[:5], all_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLibEdNPdHUI",
        "outputId": "22df8100-7238-4e05-8de2-8a782151d709"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(289,\n",
              " 289,\n",
              " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([-4.8126717], dtype=float32)>,\n",
              "  <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-8.292546], dtype=float32)>,\n",
              "  <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-5.298879], dtype=float32)>,\n",
              "  <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-6.739436], dtype=float32)>,\n",
              "  <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-8.063936], dtype=float32)>],\n",
              " [<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
              "  <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
              "  <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
              "  <tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
              "  <tf.Tensor: shape=(), dtype=int32, numpy=0>])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding out the best threshold for f1 score\n",
        "threshold = 0.0\n",
        "while threshold <= 1.0:\n",
        "  def thr(value, threshold):\n",
        "    if value >= threshold:\n",
        "      return 1\n",
        "    return 0\n",
        "\n",
        "  predicted_labels = [thr(value, threshold) for value in all_preds]\n",
        "  f1 = f1_score(all_labels, predicted_labels)\n",
        "  print(\"Threshold: \", threshold, \"; f1: \", f1)\n",
        "  threshold += 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkm8piTDeHfA",
        "outputId": "18bf1429-7c03-4fb2-a89b-3ad095c0b1b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.0 ; f1:  0.6875000000000001\n",
            "Threshold:  0.05 ; f1:  0.6875000000000001\n",
            "Threshold:  0.1 ; f1:  0.6875000000000001\n",
            "Threshold:  0.15000000000000002 ; f1:  0.6875000000000001\n",
            "Threshold:  0.2 ; f1:  0.6875000000000001\n",
            "Threshold:  0.25 ; f1:  0.6875000000000001\n",
            "Threshold:  0.3 ; f1:  0.6875000000000001\n",
            "Threshold:  0.35 ; f1:  0.6875000000000001\n",
            "Threshold:  0.39999999999999997 ; f1:  0.6875000000000001\n",
            "Threshold:  0.44999999999999996 ; f1:  0.6875000000000001\n",
            "Threshold:  0.49999999999999994 ; f1:  0.6875000000000001\n",
            "Threshold:  0.5499999999999999 ; f1:  0.6875000000000001\n",
            "Threshold:  0.6 ; f1:  0.6875000000000001\n",
            "Threshold:  0.65 ; f1:  0.6451612903225806\n",
            "Threshold:  0.7000000000000001 ; f1:  0.6451612903225806\n",
            "Threshold:  0.7500000000000001 ; f1:  0.6451612903225806\n",
            "Threshold:  0.8000000000000002 ; f1:  0.6451612903225806\n",
            "Threshold:  0.8500000000000002 ; f1:  0.6451612903225806\n",
            "Threshold:  0.9000000000000002 ; f1:  0.6451612903225806\n",
            "Threshold:  0.9500000000000003 ; f1:  0.6451612903225806\n"
          ]
        }
      ]
    }
  ]
}